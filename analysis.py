# [Cell 1] ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ì„¤ì •
import os
import numpy as np
import torch
import torch.nn as nn
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from tqdm import tqdm  # ì§„í–‰ìƒí™© í‘œì‹œìš©

from utils.dataloader import get_dataloader

# ê·¸ëž˜í”„ ìŠ¤íƒ€ì¼
sns.set(style="whitegrid")
colors = {'ID': 'blue', 'vOOD': 'red', 'iSUN': 'green', 'Texture': 'orange'}
plt.rcParams['figure.figsize'] = (12, 6)
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(f"Device: {device}")

# [Cell 2] ë°ì´í„° ë¡œë“œ ë° Real OOD Feature ì¶”ì¶œ

# ================= ì‚¬ìš©ìž ì„¤ì • =================
# 1. íŒŒì¼ ê²½ë¡œ ì„¤ì •
seed = 0 # 0,1,2,3,4
metric = "auroc_ma" # energy_metric
root_dir = f"./sos_rho_schedule/ce_binary_E100/seed{seed}/{metric}/cifar10"
target_feat_folder = f"feat_ce_binary_s{seed}_wrn_mode_{metric}_rho0.0-0.5_E0.1"
epoch = 100

# 2. ë°ì´í„°ì…‹ ì„¤ì •
base_data = "cifar10"
ood_datasets = ["iSUN", "texture"]  # "texture"ëŠ” ë³´í†µ 'dtd'ë¡œ ë¶ˆë¦½ë‹ˆë‹¤. (dataloader í™•ì¸ í•„ìš”)
# =============================================

# 1) ID & vOOD (Saved .npy) ë¡œë“œ
feat_dir_path = os.path.join(root_dir, target_feat_folder)
orig_path = os.path.join(feat_dir_path, f"features_ep{epoch:03d}_orig.npy")
pert_path = os.path.join(feat_dir_path, f"features_ep{epoch:03d}_pert.npy")

data_dict = {}

try:
    data_dict['ID'] = np.load(orig_path)
    data_dict['vOOD'] = np.load(pert_path)
    print(f"âœ… [Saved] ID: {data_dict['ID'].shape}, vOOD: {data_dict['vOOD'].shape}")
except FileNotFoundError:
    raise FileNotFoundError("ID/vOOD .npy íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")

# 2) Model ë¡œë“œ (Real OOD ì¶”ì¶œìš©)
# feat_ -> models_ ë¡œ ë³€í™˜í•˜ì—¬ ëª¨ë¸ ê²½ë¡œ ì¶”ë¡ 
model_folder = target_feat_folder.replace("feat_", "models_")
ckpt_path = os.path.join(root_dir, model_folder, f"model_ep{epoch}.pth")

if not os.path.exists(ckpt_path):
    raise FileNotFoundError(f"ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤: {ckpt_path}")

print(f"ðŸ”„ Loading Model from {ckpt_path}...")
# ëª¨ë¸ ì•„í‚¤í…ì²˜ëŠ” utils/config ë“±ì—ì„œ ê°€ì ¸ì˜¤ê±°ë‚˜ ì§ì ‘ ì„ ì–¸í•´ì•¼ í•¨
# ì—¬ê¸°ì„œëŠ” WideResNet ê°€ì • (import í•„ìš”)
from model.WideResNet import WideResNet 
# from model.cifar_resnet import resnet18 # ResNetì¸ ê²½ìš°

# ëª¨ë¸ ìƒì„± (Argsì— ë§žê²Œ íŒŒë¼ë¯¸í„° ìˆ˜ì • í•„ìš”)
num_classes = 10 if base_data == 'cifar10' else 100
model = WideResNet(depth=40, widen_factor=2, dropRate=0.3, num_classes=num_classes).to(device)
model.load_state_dict(torch.load(ckpt_path, map_location=device))
model.eval()

# 3) Real OOD Feature Extraction Function
def extract_features(loader, model):
    feat_list = []
    with torch.no_grad():
        for images, _ in tqdm(loader, desc="Extracting"):
            images = images.to(device)
            # model.forward_virtual(x) returns (logits, features)
            _, features = model.forward_virtual(images)
            feat_list.append(features.cpu().numpy())
    return np.concatenate(feat_list, axis=0)

# 4) Real OOD ë¡œë“œ ë° ì¶”ì¶œ ì‹¤í–‰
for ood_name in ood_datasets:
    print(f"Processing Real OOD: {ood_name}...")
    try:
        # User Provided Code Snippet
        ood_loader = get_dataloader(device=device, base_data=base_data, dataname=ood_name, batch_size=200, phase='ood')
        
        # Feature ì¶”ì¶œ
        feat_real_ood = extract_features(ood_loader, model)
        data_dict[ood_name] = feat_real_ood
        print(f"âœ… [Extracted] {ood_name}: {feat_real_ood.shape}")
        
    except Exception as e:
        print(f"âš ï¸ {ood_name} ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")

# ìµœì¢… í™•ì¸
print("\nðŸ“Š Final Data Shapes:")
for k, v in data_dict.items():
    print(f" - {k}: {v.shape}")


# [Cell 3] Activation Distribution Analysis

fig, axes = plt.subplots(1, 3, figsize=(20, 5))

# 1. Global Activation (ëª¨ë“  ê°’ íŽ¼ì³ì„œ)
for name, feat in data_dict.items():
    # ë°ì´í„°ê°€ ë„ˆë¬´ ë§Žìœ¼ë©´ downsampling
    flat_feat = feat.flatten()
    if len(flat_feat) > 100000: flat_feat = np.random.choice(flat_feat, 100000, replace=False)
    
    sns.kdeplot(flat_feat, label=name, color=colors.get(name, 'gray'), ax=axes[0], fill=True, alpha=0.1)

axes[0].set_title("1. Global Activation Value Distribution")
axes[0].set_xlabel("Activation Value")
axes[0].legend()

# 2. Sample-wise Mean Activation
for name, feat in data_dict.items():
    sample_mean = feat.mean(axis=1)
    sns.kdeplot(sample_mean, label=name, color=colors.get(name, 'gray'), ax=axes[1], fill=True, alpha=0.1)

axes[1].set_title("2. Sample-wise Mean Activation")
axes[1].set_xlabel("Mean Value")

# 3. Sample-wise Max Activation (Peak Response)
for name, feat in data_dict.items():
    sample_max = feat.max(axis=1)
    sns.kdeplot(sample_max, label=name, color=colors.get(name, 'gray'), ax=axes[2], fill=True, alpha=0.1)

axes[2].set_title("3. Sample-wise MAX Activation")
axes[2].set_xlabel("Max Value")

plt.tight_layout()
plt.show()


# [Cell 4] Feature L2 Norm Distribution

plt.figure(figsize=(10, 6))

for name, feat in data_dict.items():
    # L2 Norm ê³„ì‚°
    norms = np.linalg.norm(feat, axis=1)
    
    # Histogram ê·¸ë¦¬ê¸°
    sns.kdeplot(norms, label=f"{name} (Î¼={norms.mean():.2f})", 
                color=colors.get(name, 'gray'), fill=True, alpha=0.1)

plt.title(f"Feature L2 Norm Distribution (Epoch {epoch})")
plt.xlabel("L2 Norm (Magnitude)")
plt.ylabel("Density")
plt.legend()
plt.show()


# [Cell 5] Energy Score Analysis
# ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë¥¼ ê°€ì ¸ì™€ì„œ ëª¨ë“  Featureì— ëŒ€í•´ ì¼ê´€ë˜ê²Œ ê³„ì‚°í•©ë‹ˆë‹¤.

# FC Layer Weights ì¶”ì¶œ
state_dict = model.state_dict()
keys = state_dict.keys()
# í‚¤ ì´ë¦„ ì°¾ê¸° (fc.weight or linear.weight)
w_key = [k for k in keys if 'fc.weight' in k or 'linear.weight' in k][0]
b_key = [k for k in keys if 'fc.bias' in k or 'linear.bias' in k][0]

weight = state_dict[w_key].cpu().numpy()
bias = state_dict[b_key].cpu().numpy()
temp = 1.0

def compute_energy_numpy(features, W, b, T=1.0):
    logits = np.matmul(features, W.T) + b
    # LogSumExp trick for stability
    max_logits = np.max(logits, axis=1, keepdims=True)
    exp_logits = np.exp((logits - max_logits) / T)
    log_sum_exp = np.log(np.sum(exp_logits, axis=1)) + max_logits.squeeze() / T
    energy = -T * log_sum_exp
    return energy

plt.figure(figsize=(10, 6))

for name, feat in data_dict.items():
    energy = compute_energy_numpy(feat, weight, bias, temp)
    
    sns.kdeplot(energy, label=f"{name} (Î¼={energy.mean():.2f})", 
                color=colors.get(name, 'gray'), fill=True, alpha=0.1)

plt.title("Energy Score Distribution (Lower Energy = ID-like)")
plt.xlabel("Energy Score")
plt.ylabel("Density")
plt.legend()
plt.show()


# [Cell 6] t-SNE Visualization (Sampled)
# ì „ì²´ ë°ì´í„°ëŠ” ë„ˆë¬´ ë§Žìœ¼ë¯€ë¡œ í´ëž˜ìŠ¤ë³„ë¡œ Nê°œì”© ìƒ˜í”Œë§

n_sample_per_class = 5000
tsne_data = []
tsne_labels = []

print("Sampling data for t-SNE...")
for name, feat in data_dict.items():
    if len(feat) > n_sample_per_class:
        idx = np.random.choice(len(feat), n_sample_per_class, replace=False)
        sampled = feat[idx]
    else:
        sampled = feat
    
    tsne_data.append(sampled)
    tsne_labels.extend([name] * len(sampled))

X_all = np.concatenate(tsne_data, axis=0)
y_all = np.array(tsne_labels)

# Run t-SNE
print(f"Running t-SNE on {X_all.shape[0]} samples...")
tsne = TSNE(n_components=2, random_state=42, n_iter=1000)
X_embedded = tsne.fit_transform(X_all)

# Plotting
plt.figure(figsize=(12, 10))
for name in data_dict.keys(): # ìˆœì„œëŒ€ë¡œ ê·¸ë¦¬ê¸°
    indices = np.where(y_all == name)
    plt.scatter(X_embedded[indices, 0], X_embedded[indices, 1], 
                c=colors.get(name, 'gray'), label=name, s=15, alpha=0.6)

plt.title(f"t-SNE Visualization of Feature Space (Epoch {epoch})")
plt.legend()
plt.show()