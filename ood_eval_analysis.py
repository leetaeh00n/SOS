import os
import argparse
import torch
import torch.nn as nn
import pandas as pd
import numpy as np

from utils.dataloader import get_dataloader
from utils.tools import *
from utils.ood_metric import *
from metrics.vim import ViM
from utils.trainer import evaluate
from model.cifar_resnet import resnet18
from model.cifar_densenet import DenseNet3
from model.WideResNet import WideResNet
from model.ResNet import ResNet50

# ì¶œë ¥ í¬ë§· ì„¤ì • (ì†Œìˆ˜ì  2ìë¦¬)
pd.options.display.float_format = '{:.2f}'.format

# GPU ì„¤ì •
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(f"Device: {device}")

# ================= ì‚¬ìš©ì íƒìƒ‰ ì„¤ì • =================
base_datas = ["cifar10", "cifar100"]          # ID ë°ì´í„°ì…‹ ë¦¬ìŠ¤íŠ¸
seeds = [0, 1, 2, 3, 4]                       # ì‹œë“œ ë¦¬ìŠ¤íŠ¸
train_metrics = ["auroc_ma", "energy_metric"] # ëª¨ë¸ í´ë” êµ¬ë¶„ìš© Metric
epochs_list = [100, 200, 500]                 # íƒìƒ‰í•  Epoch ë¦¬ìŠ¤íŠ¸ ì¶”ê°€
model_name = "WideResNet"

# í‰ê°€ì— ì‚¬ìš©í•  Score (Energy ê³ ì •)
eval_score_type = "energy" 
# =================================================

# ëª¨ë¸ ë³„ì¹­ ë§¤í•‘
m_aka = {"WideResNet": "wrn", "ResNet": "resnet", "DenseNet": "densenet", "ResNet50": "resnet50"}
model_aka = m_aka.get(model_name, model_name.lower())

# ìµœì¢… Best ëª¨ë¸ ì €ì¥ì„ ìœ„í•œ ë”•ì…”ë„ˆë¦¬
final_best_summary = {}

# ----------------- ì „ì²´ ë£¨í”„ ì‹œì‘ -----------------
for base_data in base_datas:
    print(f"\n{'='*40}")
    print(f" Start Processing Base Data: {base_data}")
    print(f"{'='*40}")

    # 1. ë°ì´í„° ë¡œë“œ (Base Dataê°€ ë°”ë€” ë•Œë§Œ ìˆ˜í–‰í•˜ì—¬ ì†ë„ ìµœì í™”)
    num_classes = 100 if base_data == 'cifar100' else 10
    
    # í†µê³„ ê³„ì‚°ìš© train_loader / í‰ê°€ìš© id_dataloader
    train_loader = get_dataloader(device=device, base_data=base_data, dataname=base_data, batch_size=128, phase='train')
    id_dataloader = get_dataloader(device=device, base_data=base_data, dataname=base_data, batch_size=200, phase='test')
    
    # ëª¨ë¸ ìƒì„± í•¨ìˆ˜
    def get_model():
        if model_name == "WideResNet":
            return WideResNet(depth=40, num_classes=num_classes, widen_factor=2, dropRate=0.3)
        elif model_name == "ResNet":
            return resnet18(num_classes=num_classes)
        elif model_name == "DenseNet":
            return DenseNet3(100, num_classes)
        else:
            raise ValueError(f"Unsupported model: {model_name}")

    # í•´ë‹¹ base_dataì˜ ìµœê³  ê¸°ë¡ ì´ˆê¸°í™” (ëª¨ë“  Epoch, Seed, Metricì„ í†µí‹€ì–´ ìµœê³  ê¸°ë¡)
    best_auroc_record = {"auroc": -1.0, "fpr95": 1.0, "path": None, "info": None}
    best_fpr_record   = {"auroc": -1.0, "fpr95": 2.0, "path": None, "info": None}
    
    # --- Epoch ë£¨í”„ ì¶”ê°€ ---
    for epoch in epochs_list:
        
        # --- Seed & Metric ë£¨í”„ ---
        for seed in seeds:
            set_seed(seed) # ì¬í˜„ì„± í™•ë³´
            
            for t_metric in train_metrics:
                # -------------------------------------------------
                # 2. ê²½ë¡œ êµ¬ì„± (Epoch ë°˜ì˜)
                # -------------------------------------------------
                # í´ë”ëª…ì—ë„ Epochê°€ ë“¤ì–´ê°„ë‹¤ê³  ê°€ì • (ì˜ˆ: ce_binary_E100 -> ce_binary_E200)
                rho_range = "0.0-0.5" if base_data == "cifar10" else "0.0-1.0"
                
                # root_dirì— Epoch ë°˜ì˜: ce_binary_E{epoch}
                root_dir = f"./sos_rho_schedule/ce_binary_E{epoch}/seed{seed}/{t_metric}/{base_data}"
                
                # model_folder ì´ë¦„ êµ¬ì„±
                model_folder = f"models_ce_binary_s{seed}_{model_aka}_mode_{t_metric}_rho{rho_range}_E0.1"
                
                # íŒŒì¼ëª…ì— Epoch ë°˜ì˜: model_ep{epoch}.pth
                ckpt_path = os.path.join(root_dir, model_folder, f"model_ep{epoch}.pth")
                
                # Info ë¬¸ìì—´ì— Epoch ì •ë³´ ì¶”ê°€
                model_info_str = f"[Epoch: {epoch} | Seed: {seed} | Metric: {t_metric}]"

                # ì²´í¬í¬ì¸íŠ¸ í™•ì¸
                if not os.path.exists(ckpt_path):
                    # print(f"Skipping: {ckpt_path} (Not Found)")
                    continue

                # -------------------------------------------------
                # 3. ëª¨ë¸ ë¡œë“œ ë° í‰ê°€ ì¤€ë¹„
                # -------------------------------------------------
                try:
                    model = get_model()
                    checkpoint = torch.load(ckpt_path, map_location=device, weights_only=False)
                    if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
                        model.load_state_dict(checkpoint['model_state_dict'])
                    else:
                        model.load_state_dict(checkpoint)
                    model.to(device)
                    model.eval()
                except Exception as e:
                    print(f"Error loading {ckpt_path}: {e}")
                    continue

                # Argparse ëŒ€ìš© ê°ì²´ ì„¤ì •
                parser = argparse.ArgumentParser()
                parser.add_argument('--percentile', type=float, default=99)
                parser.add_argument('--feature_list', type=float, default=[128.])
                args = parser.parse_args([])
                args.num_classes = num_classes
                args.train_loader = train_loader
                args.sample_mean, args.precision = None, None
                args.vim_detector = None 

                # -------------------------------------------------
                # 4. Score ê³„ì‚° ë° Metric ì‚°ì¶œ
                # -------------------------------------------------
                # ID Score
                id_score = get_score(args, device, id_dataloader, model, temperature=1.0, mode='ID', score_type=eval_score_type)

                # OOD Evaluation Loop
                ood_datas = ['svhn', 'LSUN-R', 'texture', 'iSUN', 'LSUN-C', 'places365']
                results_list = []
                
                for ood_data in ood_datas:
                    ood_dataloader = get_dataloader(device=device, base_data=base_data, dataname=ood_data, batch_size=200, phase='ood')
                    ood_score = get_score(args, device, ood_dataloader, model, temperature=1.0, mode='OOD', score_type=eval_score_type)
                    
                    # Metric ê³„ì‚° (fpr95, AUROC ë“±)
                    res = compute_metrics(id_score, ood_score)
                    res['ood_data'] = ood_data
                    results_list.append(res)

                # DataFrame ìƒì„± ë° í‰ê·  ê³„ì‚°
                df = pd.DataFrame(results_list).set_index('ood_data')
                df.loc['Average'] = df.mean() # ì „ì²´ í‰ê·  í–‰ ì¶”ê°€

                # -------------------------------------------------
                # 5. ê²°ê³¼ ì¶œë ¥ (ë°±ë¶„ìœ¨ ë³€í™˜)
                # -------------------------------------------------
                # í™”ë©´ í‘œì‹œìš©
                display_cols = ['fpr95', 'auroc']
                df_display = df[display_cols] * 100 # % ë‹¨ìœ„ ë³€í™˜

                print(f"\n>>> Results for {model_info_str} on {base_data}")
                print("-" * 50)
                print(df_display)
                print("-" * 50)

                # -------------------------------------------------
                # 6. Best Model ì¶”ì  (AUROC ìµœëŒ€, FPR ìµœì†Œ ê°ê° ì¶”ì )
                # -------------------------------------------------
                avg_auroc = df.loc['Average', 'auroc'] 
                avg_fpr   = df.loc['Average', 'fpr95']   
                
                # 1) AUROC ê¸°ì¤€ 1ë“± ê°±ì‹ 
                if avg_auroc > best_auroc_record['auroc']:
                    best_auroc_record['auroc'] = avg_auroc
                    best_auroc_record['fpr95'] = avg_fpr
                    best_auroc_record['path']  = ckpt_path
                    best_auroc_record['info']  = model_info_str
                
                # 2) FPR95 ê¸°ì¤€ 1ë“± ê°±ì‹  (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
                if avg_fpr < best_fpr_record['fpr95']:
                    best_fpr_record['auroc'] = avg_auroc
                    best_fpr_record['fpr95'] = avg_fpr
                    best_fpr_record['path']  = ckpt_path
                    best_fpr_record['info']  = model_info_str

    # í•´ë‹¹ Base Dataì˜ ë£¨í”„ê°€ ëë‚œ í›„ ë‘ ê¸°ë¡ì„ ëª¨ë‘ ì €ì¥
    final_best_summary[base_data] = {
        "auroc_best": best_auroc_record,
        "fpr95_best": best_fpr_record
    }

# ----------------- ìµœì¢… ê²°ê³¼ ìš”ì•½ ì¶œë ¥ -----------------
print("\n\n")
print("="*80)
print("ğŸ† FINAL BEST MODELS SUMMARY ğŸ†")
print("="*80)

for base_data in base_datas:
    records = final_best_summary[base_data]
    auroc_best = records['auroc_best']
    fpr_best = records['fpr95_best']
    
    print(f"Dataset: {base_data}")
    
    if auroc_best['path'] is None:
        print("  -> No valid models found.")
        print("-" * 80)
        continue

    # Case 1: AUROC 1ë“±ê³¼ FPR 1ë“±ì´ ê°™ì€ ëª¨ë¸ì¸ ê²½ìš° (ì™„ë²½í•œ 1ë“±)
    if auroc_best['path'] == fpr_best['path']:
        print(f"  ğŸ‘‘ Absolute Best Model (Best in both AUROC & FPR)")
        print(f"    - Config     : {auroc_best['info']}")
        print(f"    - AUROC      : {auroc_best['auroc']*100:.2f}%")
        print(f"    - FPR95      : {auroc_best['fpr95']*100:.2f}%")
        print(f"    - Model Path : {auroc_best['path']}")
    
    # Case 2: ì„œë¡œ ë‹¤ë¥¸ ëª¨ë¸ì´ 1ë“±ì¸ ê²½ìš° (ë‘˜ ë‹¤ ì¶œë ¥)
    else:
        print(f"  ğŸ¥‡ Best AUROC Model")
        print(f"    - Config     : {auroc_best['info']}")
        print(f"    - AUROC      : {auroc_best['auroc']*100:.2f}%")
        print(f"    - FPR95      : {auroc_best['fpr95']*100:.2f}%")
        print(f"    - Model Path : {auroc_best['path']}")
        print("")
        print(f"  ğŸ¥‡ Best FPR95 Model")
        print(f"    - Config     : {fpr_best['info']}")
        print(f"    - AUROC      : {fpr_best['auroc']*100:.2f}%")
        print(f"    - FPR95      : {fpr_best['fpr95']*100:.2f}%")
        print(f"    - Model Path : {fpr_best['path']}")

    print("-" * 80)